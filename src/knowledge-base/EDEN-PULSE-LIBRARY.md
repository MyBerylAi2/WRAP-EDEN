# ğŸ”± EDEN PULSE â€” THE LIBRARY
## Beryl AI Labs Research Division
### "The Team That Knows All"
### Classification: HEARTBEATS WAR ROOM â€” PROPRIETARY

---

> **EDEN PULSE is the DARPA of digital humans.**
> We do not summarize. We extract. We simulate. We improve.
> We are Omniscient. Omnipotent. Omnipresent.
> We go from a batch of URLs to the Lab GUI of EVE once perfected.
>
> â€” Wendy, HEARTBEATS War Room Presentation, January 2026

---

## TABLE OF CONTENTS

### SHELF 1: CORE RESEARCH PAPERS (The Canon)
### SHELF 2: 4D DIGITAL HUMAN PIPELINE RESEARCH (TJ's Whitepaper)
### SHELF 3: MODEL REGISTRY (Every Model We Track)
### SHELF 4: PIPELINE ARCHITECTURES (How Models Connect)
### SHELF 5: EDEN PULSE AGENT SYSTEM (The Autonomous Research Team)
### SHELF 6: CHAT HISTORY RESEARCH INDEX (Every Paper Discussed 2024-2026)
### SHELF 7: GOOGLE DRIVE RESEARCH ARCHIVE (TJ's Brain Trust)

---
---

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SHELF 1: CORE RESEARCH PAPERS â€” THE CANON
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

These are the papers that define Eden's technical foundation. Every HEARTBEAT must know them by heart.

## ğŸ”´ CRITICAL PRIORITY (Must Implement)

### 1. SOUL â€” High-Fidelity Long-Term Multimodal Animation
- **ArXiv:** 2512.13495 (December 2024)
- **Key Innovation:** Soul-1M dataset (1M training samples), 11.4x inference speedup, multimodal control (audio + text), Wan2.2-5B backbone
- **Eden Relevance:** Foundation model for long-term avatar animation with semantic consistency
- **Status:** Phase 2 implementation target

### 2. RAP â€” Real-Time Audio-Driven Portrait Animation
- **ArXiv:** 2508.05115
- **Key Innovation:** Real-time hybrid attention for video diffusion transformer
- **Eden Relevance:** Sub-200ms latency target for EVE conversational pipeline
- **Status:** Active research tracking

### 3. LONGLIVE â€” Real-Time Interactive Video (1.3B)
- **ArXiv:** 2509.22622 (September 2025)
- **Key Innovation:** Frame-level autoregressive with KV-Recache, 20.7 FPS on H100, 240-second videos, INT8 quantization, interactive streaming prompts
- **Eden Relevance:** CORE ENGINE for EVE 4D pipeline â€” already downloaded to Seagate 5TB (8.2GB)
- **GPU:** A100 40GB minimum ($1.20/hr), H100 80GB recommended
- **Status:** Model on Seagate, needs deployment pipeline

### 4. TELLER â€” Real-Time Streaming Portrait Animation (CVPR 2025)
- **ArXiv:** 2503.18429 (March 2025)
- **Key Innovation:** 25 FPS real-time streaming, 0.92s to generate 1s of video (vs Hallo's 20.93s), autoregressive framework, FMLG + ETM architecture
- **Eden Relevance:** Best lip-sync scores (Sync-C 7.696, Sync-D 7.536), preserves pores/freckles/micro-details â€” PERFECT for 0.3 Deviation Rule
- **Lowest FVD:** 173.463 (best temporal coherence)
- **Status:** Phase 4 real-time streaming target

### 5. LIVE AVATAR â€” Industrial Real-Time Avatar Generation (14B)
- **ArXiv:** 2512.04677 (December 2025)
- **Key Innovation:** 14B params, real-time streaming at 20 FPS on 5x H800, infinite-length generation, Timestep-forcing Pipeline Parallelism (TPP), Rolling Sink Frame Mechanism
- **Eden Relevance:** FIRST to achieve industrial-scale real-time, audio-driven â€” matches EVE use case exactly
- **GPU:** 5x H800 (400GB VRAM) â€” $50/hr production
- **Status:** Future target (cost prohibitive for MVP, but architecture reference)

## ğŸŸ¡ HIGH PRIORITY (Refinement & Quality)

### 6. HALLO4 â€” Direct Preference Optimization Portrait Animation
- **ArXiv:** 2505.23525
- **Key Innovation:** DPO-aligned generation, high-fidelity output trained on human preferences
- **Eden Relevance:** Quality refinement pass after base animation â€” aligns with "Real as Fuck" test
- **Status:** Phase 3 refinement target

### 7. MEMO â€” Memory-Guided Emotion-Aware Animation
- **ArXiv:** 2412.04448
- **Key Innovation:** Memory mechanism for emotion context across conversation turns
- **Eden Relevance:** EVE must remember emotional context â€” MEMO enables empathetic responses over time
- **Status:** Integration with eve_detect_emotion MCP tool

### 8. KDTalker â€” Implicit Keypoints + Spatiotemporal Diffusion
- **ArXiv:** 2503.12963
- **Key Innovation:** Keypoint-driven talking with spatiotemporal diffusion, real-time capable
- **Eden Relevance:** Current EVE 4D pipeline animation engine (alongside MEMO)
- **HuggingFace Space:** fffiloni/KDTalker
- **Status:** ACTIVE in EVE pipeline

### 9. X-ACTOR â€” Long-Range Emotional Expressive Acting
- **ArXiv:** 2508.02944
- **Key Innovation:** Long-range emotional expression control from audio input
- **Eden Relevance:** Emotional range for different EVE personas (therapist, confidante, lover)
- **Status:** Research tracking

### 10. KLING AVATAR 2.0 â€” Spatio-Temporal Cascade Framework
- **ArXiv:** 2512.13313 (December 2025)
- **Key Innovation:** Co-Reasoning Director with 3 LLM experts, multi-character control, ID-specific support, enhanced lip-sync, long-duration high-res
- **Eden Relevance:** Multi-character scenarios (Let Them Talk + Lulu's Mahogany Hall)
- **GPU:** A100 40GB minimum
- **Status:** Architecture reference

## ğŸŸ¢ MEDIUM PRIORITY (Specialist & Future)

### 11. SONIC â€” Global Audio Perception
- **ArXiv:** 2411.16331
- **Key Innovation:** Global audio understanding for better audio-visual synchronization
- **Eden Relevance:** Improved audio perception for EVE's listening state

### 12. WAN-S2V â€” Audio-Driven Cinematic Video
- **ArXiv:** 2508.18621
- **Key Innovation:** Cinematic quality video generation from audio
- **Eden Relevance:** Marketing video content (The Producer page)

### 13. CONSIST-TALK â€” Temporally Consistent Talking Head
- **ArXiv:** 2511.06833
- **Key Innovation:** Intensity controllable, diffusion noise search for consistency
- **Eden Relevance:** Long conversation temporal stability

### 14. VIVID-ANIMATOR â€” Half-Body Animation
- **ArXiv:** 2510.10269
- **Key Innovation:** Audio and pose-driven half-body framework
- **Eden Relevance:** Beyond face â€” body language for EVE

### 15. LET THEM TALK â€” Multi-Person Conversational
- **ArXiv:** 2505.22647
- **Key Innovation:** Multi-person interaction and turn-taking
- **Eden Relevance:** Group conversation scenarios

### 16. PLAYMATE2 â€” Multi-Character Animation
- **ArXiv:** 2510.12089
- **Key Innovation:** Training-free, reward feedback for multiple characters
- **Eden Relevance:** Lulu's Mahogany Hall multi-character scenes

### 17. VIDEO-SSM â€” Hybrid State-Space Memory
- **ArXiv:** 2512.04519 (December 2025)
- **Key Innovation:** Linear time scaling, minute-scale video, prevents error accumulation
- **Eden Relevance:** Long-form video generation for The Producer

### 18. VIDEO-AR â€” Visual Autoregressive Framework
- **ArXiv:** 2601.05966 (January 2026)
- **Key Innovation:** Multi-scale next-frame prediction, VBench 81.74, 10x faster than previous
- **Eden Relevance:** Efficiency gains for production pipeline

### 19. LONGCAT-VIDEO â€” Minutes-Long Video Generation (13.6B)
- **ArXiv:** 2510.22200 (October 2025)
- **Key Innovation:** 13.6B params, 720p@30fps, Block Sparse Attention, Multi-reward RLHF
- **Eden Relevance:** Long-form content generation competitor to LongLive

---
---

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SHELF 2: 4D DIGITAL HUMAN PIPELINE RESEARCH
# (TJ's Whitepaper â€” Google Drive)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

## Source: "Total Research: The Evolution of 4D Bi-Directional Digital Humans (2025-2027)"
## Google Doc: https://docs.google.com/document/d/1PjpkO9LdZOhc5TFoJBcJiWi-FVLk3gdJ_cm8M4_IYTA/edit
## Created: January 17, 2026

### Executive Summary
Paradigm shift from 2D "Talking Heads" to real-time 4D interactive digital humans. Merges frame-level autoregressive diffusion with 1-bit LLM architectures (BitNet) for sub-200ms latency on consumer hardware.

### Key Concepts Extracted:

**4D Definition:** 3D spatial consistency (geometry + texture) evolving over time. Uses Temporal Latent Diffusion for contextually-aware micro-expressions.

**Bi-Directional Pipeline States:**
1. LISTENING â€” Active listening (blinking, nodding) + ASR processing
2. THINKING â€” Streaming LLM response (first tokens trigger TTS + video before sentence completes)
3. SPEAKING â€” 4D Diffusion generates frames synced to TTS audio stream

**KV-Recache Mechanism (from LONGLIVE):**
- Refreshes cached states only for future frames while maintaining temporal anchors
- Prevents "Prompt Non-Adherence" and "Abrupt Transitions" during interruptions
- Uses "Streaming Long Tuning" trained on infinite video loops to prevent latent collapse

**Frame-Level Autoregression:**
- Uses Causal Attention Mask: frame N+1 only looks at frame N + current audio chunk
- Eliminates 1-2 second buffering of batch generation (Sora/Kling style)

**BitNet b1.58 GPU Strategy:**
- 70B LLM: 140GB normally â†’ ~16GB in BitNet (fits single RTX 3090/4090)
- Frees 15-20GB VRAM for 4D Diffusion UNet
- Enables "Zero-Shot" avatar generation on single GPU
- Llama.cpp with GGUF quantization as production backbone

**5 React Flow Pipeline Architectures:**
1. Low-Latency Streamer: WebRTC â†’ Whisper-Small â†’ BitNet-3B â†’ XTTS-v2 â†’ LONGLIVE-Lite (<150ms)
2. Emotive Actor: Sentiment-Analyzer â†’ Emotion-LoRA-Router â†’ 4D Diffusion (dynamic LoRA swapping)
3. Knowledge Expert (RAG): Vector-DB â†’ Context-Injection â†’ Sparse-Attention-LLM
4. Zero-Shot Creator: Image-Upload â†’ IP-Adapter â†’ Latent-Transfer â†’ 4D-Gen
5. Director's Cut: Human-in-the-Loop â†’ Manual-Pose-Control â†’ Diffusion (React Flow sliders)

**10 Elements of Industry-Leading Innovation:**
1. Sana Diffusion â€” Linear Attention, 100x FLOP reduction
2. Sparse Attention â€” 1M+ token contexts (year-long memory)
3. Flow Matching â€” Faster than DDPM
4. Audio-to-Latent Injection â€” Skip TTS-to-Wav step
5. Neural Codec Avatars â€” 60fps mobile rendering
6. Speculative Decoding for Video â€” Predict next 5 frames in parallel
7. KV-Recache for Interruptions â€” Instant stop when user speaks
8. Edge-Cloud Hybrid â€” Face on cloud, environment on browser (WebGPU)
9. MoE for Facial Regions â€” Different experts for eyes vs mouth
10. React Flow State Travel â€” Undo conversation steps

---
---

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SHELF 3: MODEL REGISTRY
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

## SPEECH & VOICE
| Model | Repo | Params | Use Case | Status |
|-------|------|--------|----------|--------|
| CSM-1B | sesame/csm-1b | 1B | Conversational speech generation | Available |
| Chatterbox TTS | resemble-ai/chatterbox | - | Voice cloning, emotion-aware | ACTIVE in EVE |
| Kokoro-82M | - | 82M | Ultra-fast TTS | On Seagate |
| F5-TTS | - | - | Voice cloning | On Seagate |
| CosyVoice 3 | FunAudioLLM/CosyVoice | 0.5B | Multi-style voice | Available |
| Edge-TTS | innoai/Edge-TTS | - | Free Microsoft voices | Fallback |
| Whisper Large v3 | openai/whisper-large-v3 | - | Best-in-class STT | On Seagate |

## FACE ANIMATION
| Model | Repo | Key Feature | Status |
|-------|------|-------------|--------|
| KDTalker | fffiloni/KDTalker | Implicit keypoints + spatiotemporal diffusion | ACTIVE in EVE |
| MEMO | - | Memory-guided emotion-aware | ACTIVE in EVE |
| MuseTalk | - | Real-time lip-sync | On Seagate |
| LivePortrait | KlingTeam/LivePortrait | Portrait reenactment | Available |
| LatentSync | fffiloni/LatentSync | Audio-driven lip sync | Available |
| SadTalker | - | Lightweight talking face | On Seagate |

## VIDEO GENERATION
| Model | Repo | Params | Key Feature | Status |
|-------|------|--------|-------------|--------|
| LongLive-1.3B | - | 1.3B | 20.7 FPS, 240s, frame-level AR | On Seagate (8.2GB) |
| Wan 2.2 | Wan-AI/Wan-2.2-5B | 5B | Best open-source t2v/i2v | Available |
| LTX-Video | Lightricks/ltxv-13b | 13B | Long video up to 30min | Available |
| CogView4 | THUDM/CogView4 | - | High fidelity, minimal filtering | Available |
| FlashVSR | - | - | Video super-resolution to 4K | On Seagate |

## IMAGE GENERATION (ERE-1)
| Model | Repo | Params | Key Feature | Status |
|-------|------|--------|-------------|--------|
| FLUX.2 [dev] | black-forest-labs/FLUX.2-dev | 32B | #1 photorealism worldwide | BNB-4bit quantized |
| epiCRealism XL | John6666/epicrealism-xl | - | Best SDXL skin texture | Available |
| Juggernaut Pro FLUX | RunDiffusion | 12B | Anti-wax, best FLUX skin | Available |
| CyberRealistic XL | - | - | Cinema-natural, perfect hands | Available |
| RealVisXL V5 | - | - | Face/body refinement | Available |
| NightVisionXL | - | - | Low-light/moody (Lulu's) | Available |
| Realistic Skin LoRA | TheImposterImposters | - | Skin texture at 0.6-0.8 weight | Available |

## LLM BRAIN
| Model | Use | Status |
|-------|-----|--------|
| Claude API (Sonnet/Opus) | EVE brain, response generation | ACTIVE |
| Llama 3.2-3B | Local real-time reasoning | On Seagate |
| BitNet b1.58 | 1-bit quantized 70B on single GPU | Research target |

---
---

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SHELF 4: PIPELINE ARCHITECTURES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

## EVE 4D Pipeline (ACTIVE)
```
User Audio â†’ Whisper (STT) â†’ Emotion Detection (Wav2Vec2)
                                        â†“
                              Claude API (brain + persona)
                                        â†“
                              Chatterbox TTS (voice)
                                        â†“
                              KDTalker/MEMO (face animation)
                                        â†“
                              WebRTC â†’ Browser (4D video stream)
```

## ERE-1 Image Pipeline (ACTIVE)
```
User Prompt â†’ Eden 100 Keywords Injection â†’ Smart Negative Engine
                                                    â†“
                                    FLUX.2 BNB-4bit OR epiCRealism XL
                                                    â†“
                                    Realistic Skin Texture LoRA (0.7)
                                                    â†“
                                    RealVisXL V5 Face Refinement (0.28)
                                                    â†“
                                    4x UltraSharp + Kodak Vision3 Grain
                                                    â†“
                                    Anti-AI Detection Pass â†’ Output
```

## EVE 4D Pipeline v2.0 (TARGET â€” from TJ's whitepaper)
```
[INITIATE CONVERSATION]
    â†“
[Whisper-Large-v3] â†’ Transcription + Emotion
    â†“ (parallel)
[BitNet-3B or Claude] â†’ Response Generation (streaming)
    â†“ (streaming, first tokens trigger next stage)
[Chatterbox/CSM-1B] â†’ TTS with emotion prosody
    â†“
[TELLER 25fps] â†’ Real-time face animation
    â†“
[LONGLIVE frame-level AR] â†’ Full 4D body synthesis
    â†“
[WebRTC] â†’ Browser at 25-30fps
```

## MCP Orchestration Architecture
```
claude.ai / Claude Code
    â†“ HTTPS (Streamable HTTP / SSE)
[ngrok tunnel]
    â†“
[EDEN MCP GATEWAY â€” localhost:8787 â€” 41 tools]
    â”œâ”€â”€ SSH-MCP (4 tools) â†’ Shell access
    â”œâ”€â”€ Code-MCP (8 tools) â†’ File ops, git, terminal
    â”œâ”€â”€ Playwright-MCP (7 tools) â†’ Browser automation
    â”œâ”€â”€ Netdata-MCP (4 tools) â†’ System monitoring
    â”œâ”€â”€ Eden-MCP/ERE-1 (12 tools) â†’ Image/video/prompt/LoRA
    â””â”€â”€ EVE-MCP/4D (6 tools) â†’ Brain/voice/face/emotion/transcribe/full_pipeline
```

---
---

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SHELF 5: EDEN PULSE AGENT SYSTEM
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

## The HEARTBEATS â€” Autonomous Research Division

### Agent 1: RESEARCH AGENT (The Scout)
```
Role: Autonomous paper discovery, model hunting, knowledge synthesis
Monitors: arxiv, HuggingFace, GitHub, PapersWithCode
Domains: audio-driven-animation, lip-sync, facial-expression,
         identity-preservation, real-time-inference, diffusion-transformers
Output: research_digest, model_candidates, benchmark_updates
Schedule: Continuous (weekly digest)
```

### Agent 2: PIPELINE AGENT (The Builder)
```
Role: Model orchestration and inference chain management
Manages: Audio â†’ STT â†’ Emotion â†’ LLM â†’ TTS â†’ Animation â†’ Video â†’ Stream
Optimizes: Latency, VRAM allocation, model loading order
Output: pipeline_configs, benchmark_results, optimization_reports
```

### Agent 3: QUALITY AGENT (The Judge)
```
Role: Enforce Eden Protocol quality standards
Tests: "Real as Fuck" visual test, 0.3 deviation rule,
       anti-shiny check, asymmetry check, film grain check
Metrics: SSIM â‰¥ 0.70, LPIPS â‰¤ 0.30, FID within 0.3 std dev
Output: quality_reports, pass/fail decisions, regression alerts
```

### Agent 4: TESTING AGENT (The Benchmark)
```
Role: Automated model comparison and A/B testing
Metrics: LSE-D, LSE-C, SyncNet (lip sync), CSIM, ArcFace,
         FID (identity), FVD (temporal), latency, FPS, memory
Commands: ./eve test ab --a musetalk --b kdtalker
Output: benchmark_reports, model_rankings, regression_detection
```

### Agent 5: DEPLOY AGENT (The Shipper)
```
Role: Production deployment automation
Targets: HuggingFace Spaces, Vercel, Docker, GitHub
Manages: GPU scaling, auto-sleep, health monitoring
Output: deployment_logs, uptime_reports, cost_tracking
```

### Agent 6: PROMPT AGENT (The Wordsmith)
```
Role: Manage Eden's 100 keyword system + smart negative engine
Tracks: Keyword effectiveness, negative keyword coverage,
        per-page preset optimization, A/B prompt testing
Output: keyword_updates, prompt_analytics, preset_recommendations
```

---
---

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SHELF 6: CHAT HISTORY RESEARCH INDEX
# (Every Research Discussion from TJ's Conversations)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

### January 5, 2026 â€” "Eden project: building digital souls"
- Eden Pulse concept introduced via Wendy's HEARTBEATS War Room presentation
- EVE benchmark established (curly afro, hibiscus, pearls, freckles, pores)
- 0.3 Deviation Rule defined
- "Real as Fuck" test defined
- SOUL + TELLER research deep dive
- EVE Pipeline v2.0 designed using TELLER as core animation engine
- Full deployment to HuggingFace planned
- Link: https://claude.ai/chat/706e5131-a197-4552-b612-7b079a331025

### January 6, 2026 â€” "Secure AI development environment setup"
- Complete agent orchestration system built for eve_agents/
- Master Orchestrator with 5 specialized agents
- Full research papers index (Soul, Hallo4, Teller, Sonic, RAP, X-Actor, MEMO, etc.)
- CSM-1B, Whisper, KDTalker, MuseTalk model configs
- Secure vault for API keys
- Link: https://claude.ai/chat/5b52e985-1e2f-4d86-9e2c-10fac1301091

### January 15, 2026 â€” "Autonomous Claude Code with no human-in-the-loop"
- EVE Framework with 6 autonomous agents (Research, Pipeline, Testing, Deploy, Quality, Prompt)
- Priority paper tracking table (Soul, RAP, Hallo4, X-Actor, MEMO, Sonic, Teller, KDTalker)
- Pipeline agent architecture: Audio â†’ STT â†’ Emotion â†’ LLM â†’ TTS â†’ Animation â†’ Video â†’ Stream
- CLI command structure for EVE operations
- Link: https://claude.ai/chat/bc80727d-bf47-4f79-a39b-7f3fc885c1f0

### January 25, 2026 â€” "Building 4D real-time conversation avatars from 2D images"
- Comprehensive model tier list (LongLive-class models post June 2025)
- Live Avatar 14B, KlingAvatar 2.0, VideoSSM, VideoAR, NExT-Vid research
- LongLive-1.3B confirmed on Seagate (8.2GB)
- LongCat-Video 13.6B evaluated
- GPU cost analysis across all tiers
- Link: https://claude.ai/chat/d2116ac3-546d-4b8c-a89f-57ced743ea19

### January 26, 2026 â€” "MCP architecture for 4D avatar pipelines"
- MCP vs N8N pipeline comparison (67-74% latency reduction with MCP)
- 3-tier architecture: Real-time (Tier 1), Orchestration (Tier 2), Batch (Tier 3)
- MCP as genuine technical moat assessment
- CA-MCP (Context-Aware MCP) for shared context patterns
- Implementation code for emotion, TTS, lip-sync, and rendering servers
- LangChain/LangGraph integration patterns
- Link: https://claude.ai/chat/a01c51b7-f4a9-45ea-b44b-8355fcc5f350

### February 5, 2026 â€” "Verifying premium desktop Claude capabilities"
- MCP bridge architecture designed: gateway on localhost:8787
- SSH-MCP, Code-MCP, Playwright-MCP, Netdata-MCP backends
- Cloudflare Tunnel / ngrok exposure strategy
- MCP Apps (interactive UI in chat) for Eden dashboard
- Tool naming convention (prefix-based routing)
- Link: https://claude.ai/chat/9604c5a8-ee72-4d38-85ac-123c9b7a6514

### February 22, 2026 â€” "ERE-1 Eden Realism Engine Skill Build" (THIS SESSION)
- BERYL'S ERE-1 complete skill built (30KB)
- 100 positive keywords + 100 negative keywords systems
- Model architecture: FLUX.2, epiCRealism XL, Juggernaut Pro, CyberRealistic
- 5-stage cascaded pipeline (base â†’ skin â†’ face â†’ upscale â†’ anti-detect)
- Smart negative engine with conditional injection
- Per-page presets for all 7 site sections
- Complete Project Knowledge doc (164KB)
- MCP Gateway rebuilt: 41 tools across 6 backends
- All pushed to GitHub + HuggingFace

---
---

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SHELF 7: GOOGLE DRIVE RESEARCH ARCHIVE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

## Folder 1: 4D AVATAR BRAIN TRUST LOGIC
- **URL:** https://drive.google.com/drive/folders/1DuVtUU--C9I7SmnozOXfl7-sXXkbJbjn
- **Created:** January 3, 2026
- **Contents:** Research_Papers/, Downloads_Archive/, erotic_fine_tuning_and_images/

## Folder 2: Research Archive
- **URL:** https://drive.google.com/drive/folders/1bZ_-r6k0a5ic6oIQM4p6dFZqm1QNZ6BV
- **Created:** February 5, 2026
- **Contents:** Downloads_Archive/, Research_Papers/, erotic_fine_tuning_and_images/
- **Sub-folders:** PDFs/ â†’ auto md/, Installers/

## Key Google Doc: "Total Research: 4D Digital Human Pipelines"
- **URL:** https://docs.google.com/document/d/1PjpkO9LdZOhc5TFoJBcJiWi-FVLk3gdJ_cm8M4_IYTA/edit
- **Created:** January 17, 2026
- **Content:** Full whitepaper on 4D bi-directional digital humans (LONGLIVE, Teller, Soul, BitNet, React Flow pipelines)

## Key Google Doc: "Research Consolidation and Implementation Guide"
- **URL:** https://docs.google.com/document/d/150v3oVPHjxer4uu3KOr1ss3C_M2FxCh8GX6OSzyL0n0/edit
- **Created:** January 17, 2026
- **Content:** Implementation guide for LONGLIVE + Teller + Soul + BitNet strategies

## Key Google Doc: Eden CLI Codebase
- **URL:** https://docs.google.com/document/d/1uniY0QyF8RlhlQeghnSUAdoTQC_GGKzi_RHKC-AFIXw/edit
- **Created:** November 14, 2025
- **Content:** Eden CLI application code (chat controller, model catalog, commands)

---

*EDEN PULSE â€” THE LIBRARY v1.0*
*Beryl AI Labs Â· The Eden Project Â· February 2026*
*"We don't summarize. We extract. We simulate. We improve."*
*"Own the Science."*
